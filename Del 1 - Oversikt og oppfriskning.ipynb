{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 1 - Oversikt over embedding-based retrival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Velkommen! Noen få notater om notebooken:\n",
    " - En del advarsel kan dukke opp under kjøring. Disse er bare å ignorere\n",
    " - Noen operasjoner som å kalle en LLM eller en operasjon for å generere data gir ikke-deterministiske svar så om du får forskjellig fra sidemann så er det helt vanlig.\n",
    "\n",
    "Nyt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Det er noen utility funksjoner i helper utils. Det er bare for å forenkle litt.\n",
    "from helper_utils import word_wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Enkel Arkitektur-skisse](images/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som vi kanskje husker fra en tidligere workshop i fjor er RAG en kraftig metode for å fore LLM applikasjoner med proprietære data og øke treffsikkerhet. En kjapp forklaring av skissen:\n",
    "1. Vi tar først vår rådata, om det så er strukturet i tabeller eller ustrukturert i filer som PDF og gjør det om det til et leselig format, ie strings\n",
    "2. Chunker så opp disse tekstene på en gitt størrelse og kjører de gjennom en embedder som omformer de til vektorer. Disse vektorene fanger forhåpentligvis opp semantisk likhet. Disse lagres så i en vektordatabase med påfølgende metadata. Når alt dette er på plass har vi i grunn fundamentet på plass\n",
    "3. Fra den andre siden kommer spørringer. Disse kan vi også embedde til vektorer for så å måle likhet. Semantisk like tekster vil forhåpentligvis bli plassert i geometrisk nærhet. Herfra er det enkle operasjoner for å hente de mest like.\n",
    "4. Med de mest like i hånd kan syntetisere en \"smartere\" spørring mot LLMen. Vi tar eksempelvis den mest like teksten fra vektordatabasen og legger den til i spørringen for å gi den kontekst før det blir sendt til en LLM for respons.\n",
    "\n",
    "Liten gjennomgang i kode nedenfor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trekker ut ordene fra pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Dear shareholders, colleagues, customers, and partners:  \n",
      "We are\n",
      "living through a period of historic economic, societal, and\n",
      "geopolitical change. The world in 2022 looks nothing like \n",
      "the world in\n",
      "2019. As I write this, inflation is at a 40 -year high, supply chains\n",
      "are stretched, and the war in Ukraine is \n",
      "ongoing. At the same time, we\n",
      "are entering a technological era with the potential to power awesome\n",
      "advancements \n",
      "across every sector of our economy and society. As the\n",
      "world’s largest software company, this places us at a historic\n",
      "\n",
      "intersection of opportunity and responsibility to the world around us.\n",
      " \n",
      "Our mission to empower every person and every organization on the\n",
      "planet to achieve more has never been more \n",
      "urgent or more necessary.\n",
      "For all the uncertainty in the world, one thing is clear: People and\n",
      "organizations in every \n",
      "industry are increasingly looking to digital\n",
      "technology to overcome today’s challenges and emerge stronger. And no\n",
      "\n",
      "company is better positioned to help them than Microsoft.  \n",
      "Every day\n",
      "this past fiscal year I have had the privilege to witness our customers\n",
      "use our platforms and tools to connect \n",
      "what technology can do with\n",
      "what the world needs  it to do.  \n",
      "Here are just a few examples:  \n",
      "•\n",
      "Ferrovial, which builds and manages some of the world’s busiest\n",
      "airports and highways, is using our cloud \n",
      "infrastructure to build\n",
      "safer roads as it prepares for a future of autonomous transportation. \n",
      "\n",
      "• Peace Parks Foundation, a nonprofit helping protect natural\n",
      "ecosystems in Southern Africa, is using Microsoft \n",
      "Dynamics 365 and\n",
      "Power BI to secure essential funding, as well as our Azure AI and IoT\n",
      "solutions to help \n",
      "rangers scale their park maintenance and wildlife\n",
      "crime prevention work.  \n",
      "• One of the world’s largest robotics\n",
      "companies, Kawasaki Heavy Industries, is using the breadth of our tools\n",
      "—\n",
      "from Azure IoT and HoloLens —to create an industrial metaverse\n",
      "solution that brings its distributed workforce \n",
      "together with its\n",
      "network of connected equipment to improve productivity and keep\n",
      "employees safe.  \n",
      "• Globo, the biggest media and TV company in Brazil,\n",
      "is using Power Platform to empower its employees to \n",
      "build their own\n",
      "solutions for everything from booking sets to setting schedules.  \n",
      "•\n",
      "And Ørsted, which produces a quarter of the world’s wind energy, is\n",
      "using the Microsoft Intelligent Data \n",
      "Platform to turn data from its\n",
      "offshore turbines into insights for predictive maintenance.  \n",
      "Amid this\n",
      "dynamic environment, we delivered record results in fiscal year 2022:\n",
      "We reported $198  billion in revenue and \n",
      "$83 billion in operating\n",
      "income. And the Microsoft Cloud surpassed $100  billion in annualized\n",
      "revenue for the first time.  \n",
      "OUR RESPONSIBILITY  \n",
      "As a corporation,\n",
      "our purpose and actions must be aligned with addressing the world’s\n",
      "problems, not creating new ones. \n",
      "At our very core, we need to deliver\n",
      "innovation that helps drive broad economic growth. We, as a company,\n",
      "will do well \n",
      "when the world around us does well.  \n",
      "That’s what I\n",
      "believe will lead to widespread human progress and ultimately improve\n",
      "the lives of everyone. There is no \n",
      "more powerful input than digital\n",
      "technology to drive the world’s economic output. This is the core\n",
      "thesis for our being as a \n",
      "company, but it’s not enough. As we drive\n",
      "global economic growth, we must also commit to creating a more\n",
      "inclusive, \n",
      "equitable, sustainable, and trusted future.  \n",
      "Support\n",
      "inclusive economic growth  \n",
      "We must ensure the growth we drive reaches\n",
      "every person, organization, community, and country. This starts with\n",
      "\n",
      "increasing access to digital skills. This year alone, more than 23 \n",
      "million people accessed digital skills training as part of \n",
      "our global\n",
      "skills initiative.\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"microsoft_annual_report_2022.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "#Filtrerer ut tomme strings\n",
    "pdf_texts = [text for text in pdf_texts if text]\n",
    "\n",
    "print(word_wrap(pdf_texts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitter teksten i chunkz. Som vi kommer litt tilbake til så gjør vi dette fordi vi ikke vil ta med alt for mye inn til syntetisering. Bare det som er relevant er nyttig. Resten er støy og kan verste tilfelle gjøre responsen verre. Bruker både CharacterTextSplitter og SentenceTextSplitter for å få hver chunk på ønsket format og ønsket token lengde. Det siste er litt viktig fordi embeddingmodellen tar 256 tokens, mens resten blir truncated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increased, due in large part to significant global datacenter\n",
      "expansions and the growth in Xbox sales and usage. Despite \n",
      "these\n",
      "increases, we remain dedicated to achieving a net -zero future. We\n",
      "recognize that progress won’t always be linear, \n",
      "and the rate at which\n",
      "we can implement emissions reductions is dependent on many factors that\n",
      "can fluctuate over time.  \n",
      "On the path to becoming water positive, we\n",
      "invested in 21 water replenishment projects that are expected to\n",
      "generate \n",
      "over 1.3  million cubic meters of volumetric benefits in nine\n",
      "water basins around the world. Progress toward our zero waste\n",
      "\n",
      "commitment included diverting more than 15,200 metric tons of solid\n",
      "waste otherwise headed to landfills and incinerators, \n",
      "as well as\n",
      "launching new Circular Centers to increase reuse and reduce e -waste at\n",
      "our datacenters.  \n",
      "We contracted to protect over 17,000 acres of land\n",
      "(50% more than the land we use to operate), thus achieving our\n",
      "\n",
      "Total chunks: 347\n"
     ]
    }
   ],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "print(word_wrap(character_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trekker så ut setninger og embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenanmahic/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/kenanmahic/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increased, due in large part to significant global datacenter\n",
      "expansions and the growth in xbox sales and usage. despite these\n",
      "increases, we remain dedicated to achieving a net - zero future. we\n",
      "recognize that progress won ’ t always be linear, and the rate at which\n",
      "we can implement emissions reductions is dependent on many factors that\n",
      "can fluctuate over time. on the path to becoming water positive, we\n",
      "invested in 21 water replenishment projects that are expected to\n",
      "generate over 1. 3 million cubic meters of volumetric benefits in nine\n",
      "water basins around the world. progress toward our zero waste\n",
      "commitment included diverting more than 15, 200 metric tons of solid\n",
      "waste otherwise headed to landfills and incinerators, as well as\n",
      "launching new circular centers to increase reuse and reduce e - waste\n",
      "at our datacenters. we contracted to protect over 17, 000 acres of land\n",
      "( 50 % more than the land we use to operate ), thus achieving our\n",
      "\n",
      "Total chunks: 349\n"
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "print(word_wrap(token_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sentence Transformer](images/SentenceTransformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi bruker en enkel sentence transformer modell for embeddingene. Den er i grunn bare en utvidet versjon av BERT. Der hvor BERT vektoriserer hver enkel token og returnerer det tar sentence transformeren og vektoriserer en hel setning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04256267473101616, 0.0332118384540081, 0.030340105295181274, -0.03486659750342369, 0.0684165358543396, -0.08090916275978088, -0.015474417246878147, -0.001450875774025917, -0.01674446277320385, 0.06770766526460648, -0.050541382282972336, -0.04919533431529999, 0.051399923861026764, 0.09192726761102676, -0.07177833467721939, 0.039519742131233215, -0.012833529151976109, -0.024947531521320343, -0.046228647232055664, -0.024357518181204796, 0.033949632197618484, 0.025502441450953484, 0.02731708437204361, -0.00412622420117259, -0.03633838891983032, 0.003690858604386449, -0.027430452406406403, 0.0047967275604605675, -0.028896227478981018, -0.01887073740363121, 0.036666277796030045, 0.02569585293531418, 0.031312838196754456, -0.06393437087535858, 0.053944025188684464, 0.08225345611572266, -0.04175688326358795, -0.006995797622948885, -0.023485984653234482, -0.030747996643185616, -0.002979220123961568, -0.07790941745042801, 0.009353134781122208, 0.0031628424767404795, -0.022257106378674507, -0.018294665962457657, -0.009612456895411015, -0.03150685876607895, -0.005519645754247904, -0.03270301595330238, 0.16802974045276642, -0.04745965823531151, -0.05001683533191681, -0.002659675432369113, -0.04104718938469887, -0.07003947347402573, 0.018295926973223686, -0.031431134790182114, -0.04741116240620613, -0.023663604632019997, 0.05944952368736267, -0.07201442122459412, 0.004945204593241215, -0.05532696843147278, 0.08745480328798294, 0.027872664853930473, -0.03977256640791893, 0.03452996537089348, -0.09992025792598724, 0.03289762884378433, -0.057804182171821594, 0.0024546566419303417, -0.02789231576025486, -0.04994707554578781, -0.04058242216706276, 0.01191752776503563, 0.020419061183929443, 0.07765396684408188, 0.06351622194051743, 0.01754685677587986, 0.023460984230041504, -0.007916556671261787, 0.01707419939339161, 0.00864122062921524, -0.06815341114997864, 0.034296199679374695, 0.0006465172627940774, 0.02273537777364254, 0.05279362201690674, -0.05857320874929428, -0.09784102439880371, -0.0014718812890350819, 0.1373988687992096, 0.0020795087330043316, -0.07581514865159988, 0.05786573141813278, -0.06069640815258026, -0.06595760583877563, -0.03365056589245796, -0.03185923025012016, 0.01226658932864666, 0.09373298287391663, 0.06799506396055222, -0.08434035629034042, 0.04402467980980873, -0.04263874515891075, 0.011163060553371906, 0.10505213588476181, 0.029505835846066475, -0.018521113321185112, -0.029688267037272453, -0.033770278096199036, 0.001496640034019947, 0.03732365742325783, -0.020249756053090096, 0.05842074379324913, -0.039791539311409, -0.021219685673713684, 0.006418104283511639, -0.010290166363120079, 0.019626135006546974, 0.0036797281354665756, -0.05031098052859306, -0.016897063702344894, 0.048545029014348984, 0.0668230876326561, 0.01953635923564434, 2.7227529327585318e-33, -0.03593407943844795, 0.01566188782453537, 0.0967765524983406, -0.00028518991894088686, -0.009768499992787838, -0.09068471938371658, 0.01448627095669508, 0.01259069424122572, 0.025435876101255417, -0.03443484008312225, 0.004262915346771479, 0.02712138555943966, -0.0204099602997303, 0.07688486576080322, 0.03572103753685951, -0.13492535054683685, 0.05657849833369255, 0.018364490941166878, 0.022577913478016853, -0.035890307277441025, -0.011456728912889957, -0.049938321113586426, -0.01601240411400795, -0.06335369497537613, 0.10463959723711014, -0.0880160853266716, -0.00446227565407753, -0.010301053524017334, -0.017630767077207565, -0.020292263478040695, 0.006704217288643122, 0.09172345697879791, -0.007795051671564579, 0.005949533078819513, -0.015348835848271847, 0.01827961392700672, -0.018921490758657455, 0.03987526521086693, -0.003967330325394869, 0.03341929242014885, -0.056077226996421814, 0.07581256330013275, -0.005625491961836815, -0.0544552281498909, 0.06698443740606308, -0.025974389165639877, 0.11199556291103363, -0.03642137348651886, 0.005012575536966324, 0.03200997784733772, 0.04963689669966698, 0.09711598604917526, -0.11546947807073593, 0.06413273513317108, -0.033978719264268875, -0.0929156020283699, 0.0497547909617424, -0.08613420277833939, -0.008366324007511139, -0.013703751377761364, -0.07882801443338394, 0.019654354080557823, -0.037150461226701736, 0.014476190321147442, -0.04940313473343849, 0.05349243804812431, 0.09139011800289154, 0.03100283071398735, 0.030287640169262886, 0.021342802792787552, -0.04393773525953293, -0.04297444596886635, -0.002265068469569087, -0.021944059059023857, 0.005474566947668791, -0.010243920609354973, 0.021677955985069275, -0.027323557063937187, -0.0007881968631409109, 0.03308916091918945, -0.0074024205096066, 0.009829984977841377, 0.013544085435569286, -0.03274483606219292, 0.05601905286312103, -0.06011649966239929, 0.03112201578915119, 0.034422438591718674, 0.02655048854649067, -0.006807910278439522, -0.011054255068302155, -0.014439907856285572, 0.02278541773557663, -0.027951952069997787, -0.016209058463573456, -3.689253755225225e-33, 0.029203666374087334, 0.046704862266778946, -0.049644146114587784, 0.06324484199285507, 0.028438018634915352, -0.022357206791639328, 0.033479876816272736, -0.01847870647907257, 0.01878007873892784, 0.002411655616015196, -0.08167841285467148, 0.10084172338247299, 0.04902315512299538, 0.03646733984351158, -0.04556041210889816, -0.07049193233251572, 0.025340475142002106, -0.032679423689842224, -0.042964961379766464, -0.07251022756099701, 0.041307106614112854, 0.05049722269177437, 0.0064771901816129684, -0.003324955701828003, -0.08235663920640945, 0.0800771564245224, -0.03465393930673599, 0.008470450527966022, 0.04138946160674095, -0.010147679597139359, -0.10289667546749115, 0.045671284198760986, 0.012796059250831604, -0.06017759442329407, -0.026627862825989723, -0.09725233912467957, 0.015798667445778847, 0.07219129055738449, -0.015325869433581829, 0.0018070812802761793, 0.06039530783891678, -0.07077641785144806, -0.02127874456346035, -0.038516271859407425, -0.057411134243011475, -0.004253838211297989, 0.03280768543481827, -0.017595546320080757, 0.04975760728120804, -0.007378971204161644, -0.008354593068361282, 0.04313787817955017, -0.054291557520627975, 0.04316215589642525, 0.023688526824116707, 0.01817159727215767, 0.0928221046924591, -0.004222933202981949, -0.022514577955007553, 0.01928829960525036, -0.03684435039758682, 0.1001519188284874, 0.017764722928404808, 0.02284957841038704, -0.03967682644724846, 0.0016808414366096258, 0.05066921189427376, 0.0856492891907692, -0.026413531973958015, -0.03266860917210579, -0.036949578672647476, -0.020994018763303757, 0.017766062170267105, -0.07413070648908615, -0.024688182398676872, -0.03994894027709961, -0.024767981842160225, -0.02419409714639187, -0.010816419497132301, 0.010816034860908985, -0.03055177442729473, 0.10519369691610336, -0.008021775633096695, -0.0328962579369545, 0.1480439156293869, -0.0709429383277893, -0.05021905153989792, -0.15231893956661224, 0.022767482325434685, 0.13845954835414886, -0.07923312485218048, -0.041601020842790604, -0.09371678531169891, 0.06601827591657639, 0.04352039098739624, -4.9979703931057884e-08, -0.010548035614192486, 0.06008029729127884, 0.028823459520936012, 0.07072243839502335, 0.031575340777635574, -0.05913800746202469, 0.05488333851099014, 0.16316641867160797, 0.03475947305560112, 0.02787541225552559, 0.07126773148775101, -0.006946307606995106, -0.05290433019399643, 0.011619028635323048, -0.0268350001424551, 0.028954342007637024, 0.04344692826271057, -0.07012003660202026, -0.05879399925470352, -0.03921939805150032, -0.017293931916356087, -0.030054479837417603, -0.08112520724534988, -0.0450621172785759, 0.05249616503715515, -0.04923567175865173, 0.08052122592926025, 0.06585503369569778, -0.0006081353640183806, -0.045664072036743164, 0.030586909502744675, -0.006386043503880501, -0.03175577521324158, 0.008228817954659462, 0.010760992765426636, 0.001041301991790533, 0.019078673794865608, 0.03227986767888069, -0.0144087178632617, 0.03579796478152275, -0.0722818672657013, 0.03363296762108803, 0.006663550157099962, -0.01820622757077217, -0.020436255261301994, -0.0026353958528488874, -0.185477152466774, 0.01244930550456047, 0.02973136492073536, -0.03854850307106972, -0.009753339923918247, -0.01369436364620924, 0.009183385409414768, 0.08488918840885162, 0.1272188425064087, 0.05545993894338608, -0.04936165735125542, -0.011912016198039055, -0.05697925388813019, 0.1042008325457573, 0.057180628180503845, -0.10395048558712006, -0.023767804726958275, -0.02716897428035736]]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "print(embedding_function([token_split_texts[10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med modellen lastet er det bare å laste inn en vektordatabase å lagre dokumentene. I dette tilfellet og denne workshopen har vi valgt ChromaDB, men det fins utallige andre du kan bruke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"microsoft_annual_report_2022\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med 349 chunks i databasen er det på tide å teste ut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revenue, classified by significant product and service offerings, was\n",
      "as follows : ( in millions ) year ended june 30, 2022 2021 2020 server\n",
      "products and cloud services $ 67, 321 $ 52, 589 $ 41, 379 office\n",
      "products and cloud services 44, 862 39, 872 35, 316 windows 24, 761 22,\n",
      "488 21, 510 gaming 16, 230 15, 370 11, 575 linkedin 13, 816 10, 289 8,\n",
      "077 search and news advertising 11, 591 9, 267 8, 524 enterprise\n",
      "services 7, 407 6, 943 6, 409 devices 6, 991 6, 791 6, 457 other 5, 291\n",
      "4, 479 3, 768 total $ 198, 270 $ 168, 088 $ 143, 015 we have recast\n",
      "certain previously reported amounts in the table above to conform to\n",
      "the way we internally manage and monitor our business.\n",
      "\n",
      "\n",
      "74 note 13 — unearned revenue unearned revenue by segment was as\n",
      "follows : ( in millions ) june 30, 2022 2021 productivity and business\n",
      "processes $ 24, 558 $ 22, 120 intelligent cloud 19, 371 17, 710 more\n",
      "personal computing 4, 479 4, 311 total $ 48, 408 $ 44, 141 changes in\n",
      "unearned revenue were as follows : ( in millions ) year ended june 30,\n",
      "2022 balance, beginning of period $ 44, 141 deferral of revenue 110,\n",
      "455 recognition of unearned revenue ( 106, 188 ) balance, end of period\n",
      "$ 48, 408 revenue allocated to remaining performance obligations, which\n",
      "includes unearned revenue and amounts that will be invoiced and\n",
      "recognized as revenue in future periods, was $ 193 billion as of june\n",
      "30, 2022, of which $ 189 billion is related to the commercial portion\n",
      "of revenue. we expect to recognize approximately 45 % of this revenue\n",
      "over the next 12\n",
      "\n",
      "\n",
      "that are not sold separately. • we tested the mathematical accuracy of\n",
      "management ’ s calculations of revenue and the associated timing of\n",
      "revenue recognized in the financial statements.\n",
      "\n",
      "\n",
      "82 in addition, certain costs incurred at a corporate level that are\n",
      "identifiable and that benefit our segments are allocated to them. these\n",
      "allocated costs include legal, including settlements and fines,\n",
      "information technology, human resources, finance, excise taxes, field\n",
      "selling, shared facilities services, and customer service and support.\n",
      "each allocation is measured differently based on the specific facts and\n",
      "circumstances of the costs being allocated. segment revenue and\n",
      "operating income were as follows during the periods presented : ( in\n",
      "millions ) year ended june 30, 2022 2021 2020 revenue productivity and\n",
      "business processes $ 63, 364 $ 53, 915 $ 46, 398 intelligent cloud 75,\n",
      "251 60, 080 48, 366 more personal computing 59, 655 54, 093 48, 251\n",
      "total $ 198, 270 $ 168, 088 $ 143, 015 operating income\n",
      "\n",
      "\n",
      "47 financial statements and supplementary data income statements ( in\n",
      "millions, except per share amounts ) year ended june 30, 2022 2021 2020\n",
      "revenue : product $ 72, 732 $ 71, 074 $ 68, 041 service and other 125,\n",
      "538 97, 014 74, 974 total revenue 198, 270 168, 088 143, 015 cost of\n",
      "revenue : product 19, 064 18, 219 16, 017 service and other 43, 586 34,\n",
      "013 30, 061 total cost of revenue 62, 650 52, 232 46, 078 gross margin\n",
      "135, 620 115, 856 96, 937 research and development 24, 512 20, 716 19,\n",
      "269 sales and marketing 21, 825 20, 117 19, 598 general and\n",
      "administrative 5, 900 5, 107 5, 111 operating income 83, 383 69, 916\n",
      "52, 959 other income, net 333 1, 186 77 income before income taxes 83,\n",
      "716 71, 102 53, 036 provision for income taxes 10, 978 9, 831 8, 755\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the total revenue?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(word_wrap(document))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som du kanskje kan se nedenfor så virker det som at de fleste bitene virker relevante. La oss teste det mot OpenAI-APIet og se om responsen ser nyttig ut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, retrieved_documents, model=\"gpt-3.5-turbo\"):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total revenue for the year ended June 30, 2022, was $198,270\n",
      "million.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "\n",
    "print(word_wrap(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Har ikke dobbeltsjekket svaret men 198M virker fornuftig i mine øyne i hvert fall!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
